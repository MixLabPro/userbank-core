# 认知分析管道 (Cognitive Analysis Pipeline)

这是将用户的原始输入（无论是直接对话、文档导入还是其他形式）转化为你数据库中结构化数据的核心流程。

## 具体实现思路

### 1. 数据输入 (Data Ingestion)

定义清晰的接口，接收来自不同来源的用户数据：
- Agent 的对话日志
- 用户笔记
- 导入的文档等

### 2. 信息提取与分类 (Information Extraction & Classification)

#### 核心技术
利用 LLM 的自然语言理解能力。

#### 实现步骤

1. **预处理**
   - 清洗输入数据
   - 去除无关信息

2. **意图识别/主题建模**
   - 判断用户输入的主题和潜在意图

3. **实体识别**
   - 识别出与8张表格相关的关键实体
   - 例如：识别出一个目标、一个信念陈述、一个偏好描述

4. **关系抽取**
   - 识别不同实体间的关系
   - 例如：这个短期目标是为了支持哪个长期目标

5. **分类**
   - 将提取出的信息分类到对应的表格
   - 包括：Belief, Insight, Focus 等

#### 实现方法

##### Prompt Engineering
设计精巧的 Prompt，引导 LLM 从文本中提取和分类信息。

**通用提取示例：**
```
请分析以下文本，判断其中是否包含用户的信念、目标、偏好、洞察、决策或方法论。
如果包含，请提取出来并指明其类别。

文本：[用户输入]
```

**针对性提取：**
- 针对每一类数据设计更具体的提取 Prompt

##### Few-shot Learning
给 LLM 提供少量标注样本，让其学习如何提取和分类。

##### Fine-tuning（可选，后期）
如果数据量充足，可以考虑在特定任务上微调一个模型以提高提取精度。

### 3. 结构化与存储 (Structuring & Storage)

#### 主要任务
- 将提取和分类后的信息，按照8张表格的 schema 进行结构化
- 写入到对应的数据库表格中
- 考虑数据去重、更新逻辑（例如，用户修改了一个已有的信念）

#### 数据表格映射

| 数据类型 | 表格名称 | 描述 |
|---------|---------|------|
| 信念 | Belief | 用户的核心信念和价值观 |
| 洞察 | Insight | 用户的重要发现和理解 |
| 关注点 | Focus | 用户当前关注的重点 |
| 长期目标 | Long_term_goal | 用户的长期目标 |
| 短期目标 | Short_term_goal | 用户的短期目标 |
| 偏好 | Preference | 用户的偏好设置 |
| 决策 | Decision | 用户做出的重要决策 |
| 方法论 | Methodology | 用户采用的方法和策略 |

### 4. 验证与校准 (Validation & Calibration)

> **推荐但可选的步骤**

#### 目的
对于自动提取的信息，设计一个机制让用户确认或修正，以保证数据的准确性。

#### 实现示例
Agent 可以说：
> "我从我们刚才的谈话中理解到，你有一个新的短期目标是'学习Python编程'，对吗？"

#### 验证流程
1. **自动提取** → 系统分析用户输入
2. **生成确认** → 生成友好的确认询问
3. **用户反馈** → 用户确认或修正
4. **数据更新** → 根据反馈更新数据库

---

## 技术架构

```
用户输入 → 预处理 → LLM分析 → 信息提取 → 分类映射 → 数据存储 → 验证确认
    ↓         ↓        ↓        ↓        ↓        ↓        ↓
  原始数据   清洗数据   结构化   实体关系   表格分类   数据库   用户确认
```

## 下一步计划

- [ ] 设计具体的 Prompt 模板
- [ ] 实现数据预处理模块
- [ ] 开发信息提取算法
- [ ] 构建验证确认机制
- [ ] 测试和优化整个管道
